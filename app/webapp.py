import os
import pandas as pd
import numpy as np
import duckdb
import folium
import subprocess
import uuid
from functools import wraps

from flask import Flask, render_template, request, flash, redirect, url_for, jsonify, session
from flask_socketio import SocketIO, emit, join_room, leave_room
from task_manager import TaskManager, enqueue_data_processing_task, get_queue_status
from models import TaskStatus
from llm_cache import get_cache_stats, clear_cache
from ml_worker_filter import get_ml_filter, train_ml_filter_from_llm_log
from connection_pool import get_connection_pool_stats
from incremental_processing import get_incremental_processor

# Import√°ld a legfrissebb ker√ºlethat√°rokat gener√°lt Python f√°jlb√≥l
import sys
import os as _os
sys.path.append(_os.path.abspath(_os.path.join(_os.path.dirname(__file__), '..')))
import json

# --- Konfigur√°ci√≥ ---
# A Docker kont√©neren bel√ºli abszol√∫t el√©r√©si utakat haszn√°ljuk.
WORKSPACE_DIR = '/workspace'
APP_DIR = os.path.join(WORKSPACE_DIR, 'app')
STATIC_DIR = os.path.join(APP_DIR, 'static')
PARQUET_DIR = os.path.join(WORKSPACE_DIR, 'parquet')
RELEVANT_FILE = os.path.join(PARQUET_DIR, 'core_layer_filtered.parquet')
IRRELEVANT_FILE = os.path.join(PARQUET_DIR, 'core_layer_irrelevant.parquet')
MAP_OUTPUT_FILE = os.path.join(STATIC_DIR, 'map_render.html')

app = Flask(__name__, template_folder=APP_DIR)
app.secret_key = os.getenv('SECRET_KEY', 'supersecretkey')
ADMIN_PASSWORD = os.getenv('ADMIN_PASSWORD', 'admin123')  # Alap√©rtelmezett jelsz√≥ fejleszt√©shez

# WebSocket t√°mogat√°s real-time progress tracking-hez
socketio = SocketIO(app, cors_allowed_origins="*")

# --- Admin v√©delem dekor√°tor ---
def admin_required(f):
    """Ellen≈ërzi, hogy a felhaszn√°l√≥ be van-e jelentkezve admin-k√©nt."""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get('logged_in'):
            flash('Ehhez a funkci√≥hoz admin jogosults√°g sz√ºks√©ges!', 'warning')
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

# Task manager inicializ√°l√°sa SocketIO-val
task_manager = TaskManager(socketio)

# --- Seg√©df√ºggv√©nyek ---
def get_data(file_path):
    """Biztons√°gosan bet√∂lt egy Parquet f√°jlt, vagy √ºres DataFrame-et ad vissza."""
    if os.path.exists(file_path):
        try:
            return pd.read_parquet(file_path)
        except Exception:
            return pd.DataFrame()
    return pd.DataFrame()

# --- √ötvonalak (Routes) ---

@app.route('/')
def index():
    """A f≈ëoldal, ahonnan a feldolgoz√°st lehet ind√≠tani."""
    return render_template('index.html')

# --- Admin Login / Logout ---
@app.route('/login', methods=['GET', 'POST'])
def login():
    """Admin bejelentkez√©si oldal."""
    if request.method == 'POST':
        password = request.form.get('password')
        if password == ADMIN_PASSWORD:
            session['logged_in'] = True
            flash('Sikeres bejelentkez√©s!', 'success')
            return redirect(url_for('admin_dashboard'))
        else:
            flash('Hib√°s jelsz√≥!', 'danger')
    return render_template('login.html')

@app.route('/logout')
def logout():
    """Admin kijelentkez√©s."""
    session.pop('logged_in', None)
    flash('Sikeresen kijelentkezt√©l.', 'info')
    return redirect(url_for('index'))

@app.route('/admin')
@admin_required
def admin_dashboard():
    """Admin vez√©rl≈ëpult - csak bejelentkezve el√©rhet≈ë."""
    return render_template('admin.html')

@app.route('/run-pipeline', methods=['POST'])
@admin_required
def run_pipeline():
    """Elind√≠tja az adatfeldolgoz√°st aszinkron m√≥don RQ h√°tt√©rfeladatk√©nt."""
    try:
        # √öj feladat l√©trehoz√°sa
        task_id = task_manager.create_task()
        
        # Feladat be√ºtemez√©se a h√°tt√©rben (norm√°l m√≥d: test_mode=False)
        job_id = enqueue_data_processing_task(task_id, test_mode=False)
        
        # Sikeres v√°lasz a task_id-val
        return jsonify({
            'success': True, 
            'task_id': task_id,
            'message': 'Az adatfeldolgoz√°s elindult a h√°tt√©rben. A halad√°s k√∂vethet≈ë a /task-status API-n.'
        })
        
    except Exception as e:
        return jsonify({
            'success': False, 
            'error': str(e),
            'message': f'Hiba t√∂rt√©nt a folyamat ind√≠t√°sakor: {e}'
        }), 500

@app.route('/run-pipeline-test', methods=['POST'])
@admin_required
def run_pipeline_test():
    """Teszt feldolgoz√°s: els≈ë 100 cikk worker + els≈ë 50 LLM elemz√©s."""
    try:
        # √öj feladat l√©trehoz√°sa
        task_id = task_manager.create_task()
        
        # Feladat be√ºtemez√©se TESZT M√ìDBAN (test_mode=True)
        job_id = enqueue_data_processing_task(task_id, test_mode=True)
        
        # Sikeres v√°lasz a task_id-val
        return jsonify({
            'success': True, 
            'task_id': task_id,
            'message': f'üß™ TESZT feldolgoz√°s elindult: els≈ë 100 cikk worker + els≈ë 50 LLM elemz√©s'
        })
        
    except Exception as e:
        return jsonify({
            'success': False, 
            'error': str(e),
            'message': f'Hiba t√∂rt√©nt a folyamat ind√≠t√°sakor: {e}'
        }), 500

@app.route('/task-status/<task_id>')
def get_task_status(task_id: str):
    """Feladat st√°tusz lek√©rdez√©se API v√©gpont."""
    status = task_manager.get_status(task_id)
    if not status:
        return jsonify({'success': False, 'error': 'Feladat nem tal√°lhat√≥'}), 404
    
    return jsonify({
        'success': True,
        'status': status.model_dump()
    })

@app.route('/queue-status')
def get_queue_status_endpoint():
    """RQ queue st√°tusz inform√°ci√≥k."""
    try:
        queue_info = get_queue_status()
        return jsonify(queue_info)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# WebSocket esem√©nyek real-time friss√≠t√©sekhez
@socketio.on('subscribe_to_task')
def handle_task_subscription(data):
    """Kliens feliratkoz√°sa egy feladat st√°tusz friss√≠t√©seire."""
    task_id = data.get('task_id')
    if task_id:
        # Kliens hozz√°ad√°sa a task-specifikus room-hoz
        join_room(task_id)
        emit('subscribed', {'task_id': task_id})
        
        # Aktu√°lis st√°tusz k√ºld√©se
        status = task_manager.get_status(task_id)
        if status:
            emit('status_update', status.model_dump())

@socketio.on('unsubscribe_from_task')
def handle_task_unsubscription(data):
    """Kliens leiratkoz√°sa feladat friss√≠t√©seir≈ël."""
    task_id = data.get('task_id')
    if task_id:
        leave_room(task_id)
        emit('unsubscribed', {'task_id': task_id})

@app.route('/stats')
def stats():
    """Tov√°bbfejlesztett statisztikai oldal queue inform√°ci√≥kkal."""
    relevant_df = get_data(RELEVANT_FILE)
    irrelevant_df = get_data(IRRELEVANT_FILE)
    
    # Queue st√°tusz hozz√°ad√°sa
    try:
        queue_info = get_queue_status()
    except:
        queue_info = {'error': 'Queue inform√°ci√≥ nem el√©rhet≈ë'}
    
    stats_data = {
        'relevant_count': len(relevant_df),
        'irrelevant_count': len(irrelevant_df),
        'total_count': len(relevant_df) + len(irrelevant_df),
        'queue_info': queue_info
    }
    return render_template('stats.html', stats=stats_data)

@app.route('/data')
def data_table():
    """Megjelen√≠ti a relev√°ns adatokat egy t√°bl√°zatban."""
    """Megjelen√≠ti a relev√°ns √©s irrelev√°ns adatokat egy t√°bl√°zatban."""
    relevant_df = get_data(RELEVANT_FILE)
    irrelevant_df = get_data(IRRELEVANT_FILE)

    tables = []

    # Relev√°ns adatok
    html_chunk = "<h3>Relev√°ns hirdet√©sek</h3>"
    if not relevant_df.empty:
        df_copy = relevant_df.copy()
        if 'description' in df_copy.columns:
            df_copy['description_short'] = df_copy['description'].astype(str).str.slice(0, 150) + '...'
        html_chunk += df_copy.to_html(classes='data table table-striped', header="true", index=False, escape=False)
    else:
        html_chunk += "<p>Nincsenek relev√°ns adatok.</p>"
    tables.append(html_chunk)

    # Nem relev√°ns adatok
    html_chunk = "<h3>Nem relev√°ns hirdet√©sek</h3>"
    if not irrelevant_df.empty:
        df_copy = irrelevant_df.copy()
        if 'description' in df_copy.columns:
            df_copy['description_short'] = df_copy['description'].astype(str).str.slice(0, 150) + '...'
        html_chunk += df_copy.to_html(classes='data table table-striped', header="true", index=False, escape=False)
    else:
        html_chunk += "<p>Nincsenek nem relev√°ns adatok.</p>"
    tables.append(html_chunk)

    return render_template('data_table.html', tables=tables, titles=['Adatok'])

@app.route('/query', methods=['GET'])
def query_interface():
    """Lek√©rdez√©si fel√ºlet (SQL √©s Chat tabok)."""
    return render_template('query_interface.html')

@app.route('/sql-query', methods=['GET', 'POST'])
def sql_query():
    """SQL lek√©rdez≈ë fel√ºlet a DuckDB seg√≠ts√©g√©vel."""
    query = "SELECT district, COUNT(*) as count FROM relevant_data GROUP BY district ORDER BY count DESC;"
    results_html = None
    error = None

    if request.method == 'POST':
        query = request.form.get('query')
        try:
            if not os.path.exists(RELEVANT_FILE):
                raise FileNotFoundError("A feldolgozott adatf√°jl (core_layer_filtered.parquet) nem tal√°lhat√≥.")
            # A DuckDB k√∂zvetlen√ºl tud Parquet f√°jlokat lek√©rdezni
            con = duckdb.connect(database=':memory:', read_only=False)
            con.execute(f"CREATE OR REPLACE VIEW relevant_data AS SELECT * FROM read_parquet('{RELEVANT_FILE}');")
            result_df = con.execute(query).fetchdf()
            results_html = result_df.to_html(classes='data table table-striped', header="true", index=False)
        except Exception as e:
            error = f"Hiba a lek√©rdez√©s v√©grehajt√°sa sor√°n: {e}"

    return render_template('sql_query.html', query=query, results_html=results_html, error=error)

@app.route('/chat-query', methods=['POST'])
def chat_query():
    """LLM-alap√∫ term√©szetes nyelvi lek√©rdez√©s."""
    import ollama
    
    user_question = request.form.get('question', '').strip()
    
    if not user_question:
        return jsonify({'error': 'K√©rlek adj meg egy k√©rd√©st!'}), 400
    
    try:
        if not os.path.exists(RELEVANT_FILE):
            raise FileNotFoundError("A feldolgozott adatf√°jl nem tal√°lhat√≥.")
        
        # Adatok bet√∂lt√©se √©s s√©ma inform√°ci√≥k
        df = get_data(RELEVANT_FILE)
        if df.empty:
            return jsonify({'error': 'Nincsenek relev√°ns adatok.'}), 400
        
        # S√©ma inform√°ci√≥k az LLM sz√°m√°ra
        columns_info = ", ".join(df.columns.tolist())
        sample_data = df.head(3).to_string()
        
        # Prompt az LLM sz√°m√°ra SQL gener√°l√°shoz
        prompt = f"""Te egy SQL szak√©rt≈ë vagy. A feladatod, hogy a felhaszn√°l√≥ term√©szetes nyelvi k√©rd√©s√©re SQL lek√©rdez√©st gener√°lj.

Az adatb√°zisban egy 'relevant_data' nev≈± t√°bla van a k√∂vetkez≈ë oszlopokkal:
{columns_info}

Minta adatok:
{sample_data}

Fontos tudnival√≥k:
- Az √°r 'price_huf' oszlopban van (forintban)
- A ter√ºlet 'area_sqm' oszlopban van (n√©gyzetm√©terben)
- A ker√ºlet 'district' oszlopban van (pl. "I. ker√ºlet", "VI. ker√ºlet")
- Az id≈ëb√©lyegek: 'valid_from' (mikor lett feladva), 'valid_till' (meddig volt akt√≠v)
- Az akt√≠v hirdet√©sek: ahol valid_till >= mai d√°tum VAGY valid_till IS NULL

Felhaszn√°l√≥ k√©rd√©se: {user_question}

V√°laszolj CSAK egy √©rv√©nyes SQL SELECT utas√≠t√°ssal, semmi m√°st ne √≠rj! Ne haszn√°lj backtickeket vagy markdown form√°z√°st.
"""
        
        # LLM h√≠v√°s
        response = ollama.chat(
            model='llama3.2:3b',
            messages=[{'role': 'user', 'content': prompt}],
            options={'temperature': 0.0}
        )
        
        sql_query = response['message']['content'].strip()
        
        # SQL query tiszt√≠t√°sa (ha markdown vagy backtick van benne)
        sql_query = sql_query.replace('```sql', '').replace('```', '').strip()
        
        # SQL futtat√°sa
        con = duckdb.connect(database=':memory:', read_only=False)
        con.execute(f"CREATE OR REPLACE VIEW relevant_data AS SELECT * FROM read_parquet('{RELEVANT_FILE}');")
        result_df = con.execute(sql_query).fetchdf()
        
        # Term√©szetes nyelvi v√°lasz gener√°l√°sa
        result_summary = result_df.to_string()
        
        answer_prompt = f"""A felhaszn√°l√≥ ezt k√©rdezte: "{user_question}"

Az SQL lek√©rdez√©s eredm√©nye:
{result_summary}

Adj egy r√∂vid, term√©szetes nyelvi v√°laszt a felhaszn√°l√≥ k√©rd√©s√©re az eredm√©nyek alapj√°n. 
Ha sz√°mokat eml√≠tesz, form√°zd ≈ëket olvashat√≥an (ezres elv√°laszt√≥k). 
Ha √°rakr√≥l van sz√≥, add hozz√° a "Ft" jel√∂l√©st.
Maximum 3-4 mondat legyen a v√°lasz.
"""
        
        answer_response = ollama.chat(
            model='llama3.2:3b',
            messages=[{'role': 'user', 'content': answer_prompt}],
            options={'temperature': 0.3}
        )
        
        natural_answer = answer_response['message']['content'].strip()
        results_html = result_df.to_html(classes='data table table-striped', header="true", index=False)
        
        return jsonify({
            'answer': natural_answer,
            'sql_query': sql_query,
            'results_html': results_html
        })
        
    except Exception as e:
        return jsonify({'error': f'Hiba t√∂rt√©nt: {str(e)}'}), 500


def calculate_detailed_stats(df, data_type="relev√°ns"):
    """R√©szletes statisztik√°kat sz√°mol ki egy DataFrame-r≈ël.
    Args:
        df: A DataFrame, amelyr≈ël statisztik√°t k√©sz√≠t√ºnk
        data_type: Az adatok t√≠pusa (pl. "relev√°ns" vagy "irrelev√°ns")
    Returns:
        stats_html: HTML t√°bl√°zat a statisztik√°kkal, vagy None ha hiba t√∂rt√©nt
    """
    if df.empty:
        flash(f"Nincsenek {data_type} adatok a r√©szletes statisztik√°khoz.", "warning")
        return None

    df = df.copy()

    # Debug: ki√≠rjuk, hogy milyen oszlopok vannak az adatokban
    print(f"El√©rhet≈ë oszlopok ({data_type}): {df.columns.tolist()}")
    flash(f"Debug - El√©rhet≈ë oszlopok ({data_type}): {', '.join(df.columns.tolist()[:10])}", "info")
    
    # Aggreg√°ci√≥k dinamikus √∂ssze√°ll√≠t√°sa a KeyError elker√ºl√©se √©rdek√©ben
    aggregations = {}
    
    # Hirdet√©sek sz√°ma (URL vagy article_id alapj√°n, amelyik l√©tezik)
    count_col = 'url' if 'url' in df.columns else 'article_id'
    if count_col in df.columns:
        aggregations['hirdetesek_szama'] = (count_col, 'count')

    # Statisztik√°k csak akkor, ha az oszlop l√©tezik
    if 'price_huf' in df.columns:
        df['price_huf'] = pd.to_numeric(df['price_huf'], errors='coerce')
        aggregations['atlagar'] = ('price_huf', 'mean')
        aggregations['min_ar'] = ('price_huf', 'min')
        aggregations['max_ar'] = ('price_huf', 'max')
        aggregations['ar_szoras'] = ('price_huf', 'std')
    if 'area_sqm' in df.columns:
        df['area_sqm'] = pd.to_numeric(df['area_sqm'], errors='coerce')
        aggregations['atlag_nm'] = ('area_sqm', 'mean')
    if 'rooms' in df.columns:
        df['rooms'] = pd.to_numeric(df['rooms'], errors='coerce')
        aggregations['atlag_szobaszam'] = ('rooms', 'mean')
    if 'floor' in df.columns:
        df['floor'] = pd.to_numeric(df['floor'], errors='coerce')
        aggregations['atlag_emelet'] = ('floor', 'mean')

    # N√©gyzetm√©ter√°r - m√°r kisz√°molt oszlop haszn√°lata
    if 'price_per_sqm' in df.columns:
        df['price_per_sqm'] = pd.to_numeric(df['price_per_sqm'], errors='coerce')
        aggregations['atlag_ar_per_nm'] = ('price_per_sqm', 'mean')
        aggregations['nm_ar_szoras'] = ('price_per_sqm', 'std')
    
    # Hirdet√©si √©lettartam (ha vannak d√°tum mez≈ëk)
    if 'valid_from' in df.columns and 'valid_till' in df.columns:
        df['valid_from'] = pd.to_datetime(df['valid_from'], errors='coerce')
        df['valid_till'] = pd.to_datetime(df['valid_till'], errors='coerce')
        df['days_on_market'] = (df['valid_till'] - df['valid_from']).dt.days
        aggregations['atlag_piacido'] = ('days_on_market', 'mean')
    
    # Ingatlant√≠pusok megoszl√°sa - LLM √°ltal kinyert building_type mez≈ë haszn√°lata
    if 'building_type' in df.columns:
        df['is_tegla'] = df['building_type'] == 'tegla'
        df['is_panel'] = df['building_type'] == 'panel'
        aggregations['tegla_arany'] = ('is_tegla', lambda x: x.sum() / len(x) * 100 if len(x) > 0 else 0)
        aggregations['panel_arany'] = ('is_panel', lambda x: x.sum() / len(x) * 100 if len(x) > 0 else 0)
    
    # Lak√°s vs. h√°z megoszl√°s
    if 'property_category' in df.columns:
        df['is_lakas'] = df['property_category'] == 'lakas'
        aggregations['lakas_arany'] = ('is_lakas', lambda x: x.sum() / len(x) * 100 if len(x) > 0 else 0)
    
    # Terasz megl√©te
    if 'has_terrace' in df.columns:
        df['has_terrace'] = df['has_terrace'].astype(bool)
        aggregations['terasz_arany'] = ('has_terrace', lambda x: x.sum() / len(x) * 100 if len(x) > 0 else 0)

    if 'district' not in df.columns:
        flash(f"A csoportos√≠t√°shoz sz√ºks√©ges 'district' oszlop hi√°nyzik a {data_type} adatokb√≥l.", "danger")
        return None
    if len(aggregations) <= 1: # Ha csak a darabsz√°m van (vagy m√©g az se), nincs √©rtelme a r√©szletes statisztik√°nak
        flash(f"A {data_type} adatok nem tartalmaznak elegend≈ë numerikus oszlopot (pl. price, size) a r√©szletes statisztik√°hoz.", "warning")
        return None

    # Csoportos√≠t√°s √©s aggreg√°l√°s
    district_stats = df.groupby('district').agg(**aggregations).reset_index()

    # Eredm√©nyek form√°z√°sa a megjelen√≠t√©shez
    def format_or_na(series, format_str):
        return series.apply(lambda x: format_str.format(x) if pd.notna(x) else 'N/A')

    if 'atlagar' in district_stats.columns: district_stats['atlagar'] = format_or_na(district_stats['atlagar'], '{:,.0f} Ft')
    if 'min_ar' in district_stats.columns: district_stats['min_ar'] = format_or_na(district_stats['min_ar'], '{:,.0f} Ft')
    if 'max_ar' in district_stats.columns: district_stats['max_ar'] = format_or_na(district_stats['max_ar'], '{:,.0f} Ft')
    if 'ar_szoras' in district_stats.columns: district_stats['ar_szoras'] = format_or_na(district_stats['ar_szoras'], '{:,.0f} Ft')
    if 'atlag_nm' in district_stats.columns: district_stats['atlag_nm'] = format_or_na(district_stats['atlag_nm'], '{:,.1f} m¬≤')
    if 'atlag_szobaszam' in district_stats.columns: district_stats['atlag_szobaszam'] = format_or_na(district_stats['atlag_szobaszam'], '{:,.1f}')
    if 'atlag_emelet' in district_stats.columns: district_stats['atlag_emelet'] = format_or_na(district_stats['atlag_emelet'], '{:,.1f}')
    if 'atlag_ar_per_nm' in district_stats.columns: district_stats['atlag_ar_per_nm'] = format_or_na(district_stats['atlag_ar_per_nm'], '{:,.0f} Ft/m¬≤')
    if 'nm_ar_szoras' in district_stats.columns: district_stats['nm_ar_szoras'] = format_or_na(district_stats['nm_ar_szoras'], '{:,.0f} Ft/m¬≤')
    if 'atlag_piacido' in district_stats.columns: district_stats['atlag_piacido'] = format_or_na(district_stats['atlag_piacido'], '{:,.0f} nap')
    if 'tegla_arany' in district_stats.columns: district_stats['tegla_arany'] = format_or_na(district_stats['tegla_arany'], '{:,.1f}%')
    if 'panel_arany' in district_stats.columns: district_stats['panel_arany'] = format_or_na(district_stats['panel_arany'], '{:,.1f}%')
    if 'lakas_arany' in district_stats.columns: district_stats['lakas_arany'] = format_or_na(district_stats['lakas_arany'], '{:,.1f}%')
    if 'terasz_arany' in district_stats.columns: district_stats['terasz_arany'] = format_or_na(district_stats['terasz_arany'], '{:,.1f}%')
        
    # Oszlopnevek √°tnevez√©se
    rename_dict = {
        'district': 'Ker√ºlet', 
        'hirdetesek_szama': 'Hirdet√©sek sz√°ma', 
        'atlagar': '√Åtlag√°r', 
        'min_ar': 'Min. √°r',
        'max_ar': 'Max. √°r',
        'ar_szoras': '√År sz√≥r√°s',
        'atlag_nm': '√Åtlagos m√©ret', 
        'atlag_szobaszam': '√Åtlagos szobasz√°m', 
        'atlag_emelet': '√Åtlagos emelet',
        'atlag_ar_per_nm': '√Åtlagos nm-√°r',
        'nm_ar_szoras': 'Nm-√°r sz√≥r√°s',
        'atlag_piacido': '√Åtlagos piaci id≈ë',
        'tegla_arany': 'T√©gla ar√°ny',
        'panel_arany': 'Panel ar√°ny',
        'lakas_arany': 'Lak√°s ar√°ny',
        'terasz_arany': 'Terasz/erk√©ly ar√°ny'
    }
    existing_rename_keys = {k: v for k, v in rename_dict.items() if k in district_stats.columns}
    district_stats.rename(columns=existing_rename_keys, inplace=True)

    stats_html = district_stats.to_html(classes='data table table-striped', header="true", index=False, escape=False)
    return stats_html

@app.route('/detailed-stats')
def detailed_stats():
    """R√©szletes statisztik√°kat jelen√≠t meg a relev√°ns adatokr√≥l."""
    df = get_data(RELEVANT_FILE)
    stats_html = calculate_detailed_stats(df, "relev√°ns")
    
    if stats_html is None:
        return redirect(url_for('stats'))

    return render_template('detailed_stats.html', stats_table=stats_html, data_type="Relev√°ns")

@app.route('/detailed-stats-irrelevant')
def detailed_stats_irrelevant():
    """R√©szletes statisztik√°kat jelen√≠t meg az irrelev√°ns adatokr√≥l."""
    df = get_data(IRRELEVANT_FILE)
    stats_html = calculate_detailed_stats(df, "irrelev√°ns")
    
    if stats_html is None:
        return redirect(url_for('stats'))

    return render_template('detailed_stats.html', stats_table=stats_html, data_type="Irrelev√°ns")

@app.route('/map')
def map_view():
    """T√©rk√©pes megjelen√≠t√©s. Ker√ºlethat√°rokkal, ha a geojson f√°jl el√©rhet≈ë."""
    df = get_data(RELEVANT_FILE)
    m = folium.Map(location=[47.4979, 19.0402], zoom_start=11)
    geojson_path = os.path.join(STATIC_DIR, 'budapest_districts.geojson')
    if os.path.exists(geojson_path):
        with open(geojson_path, encoding='utf-8') as f:
            geojson_data = json.load(f)
        # Automatikusan keress√ºk meg a ker√ºletn√©v mez≈ët az els≈ë feature-ben
        name_field = None
        if geojson_data['features']:
            prop_keys = list(geojson_data['features'][0]['properties'].keys())
            for key in prop_keys:
                if key.lower() in ['name', 'nev', 'kerulet', 'ker√ºlet', 'admin_leve']:
                    name_field = key
                    break
            if not name_field:
                # fallback: els≈ë property mez≈ë
                name_field = prop_keys[0]
        else:
            name_field = 'name'
        
        # Hirdet√©sek sz√°ma ker√ºletenk√©nt
        district_counts = {}
        if not df.empty and 'district' in df.columns:
            district_counts = df.groupby('district').size().to_dict()
        
        # Popup k√©sz√≠t√©se minden ker√ºlethez
        for feature in geojson_data['features']:
            district_name = feature['properties'].get(name_field, 'Ismeretlen')
            count = district_counts.get(district_name, 0)
            popup_html = f"<b>{district_name}</b><br>Hirdet√©sek sz√°ma: {count}"
            feature['properties']['popup'] = popup_html
        
        folium.GeoJson(
            geojson_data,
            name='keruletek',
            style_function=lambda feature: {
                'fillColor': 'yellow',
                'color': 'black',
                'weight': 1,
                'fillOpacity': 0.1
            },
            highlight_function=lambda feature: {
                'fillColor': 'orange',
                'color': 'red',
                'weight': 3,
                'fillOpacity': 0.5
            },
            popup=folium.GeoJsonPopup(fields=['popup'], labels=False)
        ).add_to(m)
        flash(f"Ker√ºlethat√°rok megjelen√≠tve a geojson alapj√°n (mez≈ë: {name_field}).", "success")
    else:
        flash("A budapest_districts.geojson f√°jl nem tal√°lhat√≥ a static mapp√°ban!", "danger")
    
    # CSS injekt√°l√°s a popup tip (h√°romsz√∂g) √©s marker ikonok elt√°vol√≠t√°s√°hoz
    css = """
    <style>
    .leaflet-popup-tip {
        display: none !important;
    }
    .leaflet-marker-icon {
        display: none !important;
    }
    .leaflet-marker-shadow {
        display: none !important;
    }
    </style>
    """
    m.get_root().html.add_child(folium.Element(css))
    
    os.makedirs(STATIC_DIR, exist_ok=True)
    m.save(MAP_OUTPUT_FILE)
    return render_template('map.html', map_file='map_render.html')

@app.route('/price-trends')
def price_trends_view():
    """√Årtrend elemz√©s oldal."""
    return render_template('price_trends.html')

@app.route('/analyze-trends', methods=['POST'])
def analyze_trends():
    """√Årtrend elemz√©s futtat√°sa."""
    from price_trends import analyze_price_trends
    
    try:
        df = get_data(RELEVANT_FILE)
        if df.empty:
            return jsonify({'error': 'Nincsenek relev√°ns adatok.'}), 400
        
        # Param√©terek
        district = request.form.get('district', None)
        if district == '':
            district = None
        
        area_min = request.form.get('area_min', None)
        area_max = request.form.get('area_max', None)
        lookback_months = int(request.form.get('lookback_months', 12))
        
        if area_min:
            area_min = float(area_min)
        if area_max:
            area_max = float(area_max)
        
        # Anal√≠zis futtat√°sa
        result = analyze_price_trends(df, district, area_min, area_max, lookback_months)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': f'Hiba t√∂rt√©nt: {str(e)}'}), 500

@app.route('/prediction')
def prediction():
    """Az ML predikci√≥s oldal."""
    import pickle
    
    model_file = os.path.join(WORKSPACE_DIR, 'price_prediction_model.pkl')
    
    # Check if model exists
    model_exists = os.path.exists(model_file)
    metrics = None
    feature_importance = None
    model_name = None
    all_results = None
    
    if model_exists:
        try:
            with open(model_file, 'rb') as f:
                model_data = pickle.load(f)
            metrics = model_data.get('metrics', {})
            feature_importance = model_data.get('feature_importance', [])[:10]  # Top 10
            model_name = model_data.get('model_name', 'Unknown')
            all_results = model_data.get('all_results', [])
        except Exception as e:
            flash(f"Hiba a modell bet√∂lt√©sekor: {e}", "danger")
    
    return render_template('prediction.html', 
                         model_exists=model_exists, 
                         metrics=metrics,
                         feature_importance=feature_importance,
                         model_name=model_name,
                         all_results=all_results)

@app.route('/train-model', methods=['POST'])
@admin_required
def train_model_route():
    """Elind√≠tja a modell tan√≠t√°s√°t."""
    try:
        subprocess.Popen(["python", os.path.join(APP_DIR, 'train_model.py')])
        flash('A modell tan√≠t√°sa elindult a h√°tt√©rben. Ez n√©h√°ny percet vehet ig√©nybe.', 'info')
    except Exception as e:
        flash(f'Hiba t√∂rt√©nt a modell tan√≠t√°s ind√≠t√°sakor: {e}', 'danger')
    return redirect(url_for('prediction'))

@app.route('/predict-price', methods=['POST'])
def predict_price():
    """√Årpredikci√≥ egy adott ingatlanra."""
    import pickle
    import pandas as pd
    
    model_file = os.path.join(WORKSPACE_DIR, 'price_prediction_model.pkl')
    
    if not os.path.exists(model_file):
        return jsonify({'error': 'A modell m√©g nincs betan√≠tva!'}), 400
    
    try:
        # Load model
        with open(model_file, 'rb') as f:
            model_data = pickle.load(f)
        
        model = model_data['model']
        model_name = model_data.get('model_name', 'Unknown')
        scaler = model_data.get('scaler')
        feature_names = model_data['feature_names']
        
        # Get input from form
        area_sqm = float(request.form.get('area_sqm', 0))
        rooms = float(request.form.get('rooms', 0))
        floor = float(request.form.get('floor', 0))
        district = request.form.get('district', '')
        building_type = request.form.get('building_type', 'unknown')
        property_category = request.form.get('property_category', 'unknown')
        has_terrace = request.form.get('has_terrace', 'false') == 'true'
        
        # Create feature dataframe
        input_data = pd.DataFrame([{
            'rooms': rooms,
            'area_sqm': area_sqm,
            'floor': floor,
            'has_terrace': int(has_terrace),
            'delivery_year': 2026,
            'delivery_month': 1,
            'delivery_quarter': 1,
            'delivery_dayofweek': 0,
            'has_street_info': 0
        }])
        
        # Add district dummies
        for fname in feature_names:
            if fname.startswith('district_'):
                district_name = fname.replace('district_', '')
                input_data[fname] = 1 if district == district_name else 0
        
        # Add building type dummies
        for fname in feature_names:
            if fname.startswith('building_'):
                btype = fname.replace('building_', '')
                input_data[fname] = 1 if building_type == btype else 0
        
        # Add property category dummies
        for fname in feature_names:
            if fname.startswith('category_'):
                pcat = fname.replace('category_', '')
                input_data[fname] = 1 if property_category == pcat else 0
        
        # Ensure all features are present
        for fname in feature_names:
            if fname not in input_data.columns:
                input_data[fname] = 0
        
        # Reorder columns to match training
        input_data = input_data[feature_names]
        
        # Scale if needed (Neural Network, SVM, KNN)
        if scaler is not None:
            input_data_scaled = scaler.transform(input_data)
            predicted_log_price = model.predict(input_data_scaled)[0]
        else:
            # Predict (log scale-en van)
            predicted_log_price = model.predict(input_data)[0]
        
        # Vissza-transzform√°l√°s log-b√≥l
        predicted_price = np.exp(predicted_log_price)
        
        return jsonify({
            'predicted_price': float(predicted_price),
            'formatted_price': f'{predicted_price:,.0f} Ft',
            'price_per_sqm': f'{predicted_price/area_sqm:,.0f} Ft/m¬≤' if area_sqm > 0 else 'N/A'
        })
        
    except Exception as e:
        return jsonify({'error': f'Hiba a predikci√≥ sor√°n: {str(e)}'}), 500

# --- Cache Admin Endpointok ---

@app.route('/admin/cache')
def cache_admin():
    """Cache Admin fel√ºlet megjelen√≠t√©se"""
    return render_template('cache_admin.html')

@app.route('/admin/cache/stats')
def admin_cache_stats():
    """LLM cache statisztik√°k lek√©rdez√©se"""
    try:
        stats = get_cache_stats()
        return jsonify({
            'success': True,
            'stats': stats
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/admin/ml/stats')
def admin_ml_stats():
    """ML Worker Filter statisztik√°k lek√©rdez√©se"""
    try:
        ml_filter = get_ml_filter()
        stats = ml_filter.get_stats()
        return jsonify({
            'success': True,
            'stats': stats
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/admin/ml/retrain', methods=['POST'])
def admin_ml_retrain():
    """ML Worker Filter √∫jratan√≠t√°sa"""
    try:
        success = train_ml_filter_from_llm_log()
        if success:
            ml_stats = get_ml_filter().get_stats()
            return jsonify({
                'success': True,
                'message': f'ML filter √∫jratan√≠tva: {ml_stats["relevant_samples"]} relev√°ns, {ml_stats["irrelevant_samples"]} irrelev√°ns minta',
                'stats': ml_stats
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Nincs el√©g tr√©ningadat'
            }), 400
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/admin/connection/stats')
def admin_connection_stats():
    """HTTP Connection Pool statisztik√°k lek√©rdez√©se"""
    try:
        stats = get_connection_pool_stats()
        return jsonify({
            'success': True,
            'stats': stats
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/admin/incremental/stats')
def admin_incremental_stats():
    """Inkrement√°lis feldolgoz√°s statisztik√°k lek√©rdez√©se"""
    try:
        incremental = get_incremental_processor()
        stats = incremental.get_stats()
        return jsonify({
            'success': True,
            'stats': stats
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/admin/incremental/reset', methods=['POST'])
@admin_required
def admin_incremental_reset():
    """Inkrement√°lis metadata t√∂rl√©se (teljes √∫jrafeldolgoz√°shoz)"""
    try:
        incremental = get_incremental_processor()
        incremental.reset_metadata()
        return jsonify({
            'success': True,
            'message': 'Inkrement√°lis metadata t√∂r√∂lve - k√∂vetkez≈ë futtat√°s teljes feldolgoz√°s lesz'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/admin/cache/clear', methods=['POST'])
@admin_required
def admin_cache_clear():
    """LLM cache tartalm√°nak t√∂rl√©se"""
    try:
        count = clear_cache()
        return jsonify({
            'success': True,
            'message': f'Cache t√∂r√∂lve: {count} elem',
            'cleared_count': count
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    # SocketIO-val ind√≠t√°s WebSocket t√°mogat√°s√©rt
    # A 0.0.0.0 host sz√ºks√©ges, hogy a Docker kont√©neren k√≠v√ºlr≈ël is el√©rhet≈ë legyen.
    socketio.run(app, host='0.0.0.0', port=5001, debug=True, allow_unsafe_werkzeug=True)