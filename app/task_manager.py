"""
H√°tt√©rfeladat kezel≈ë RQ (Redis Queue) alap√∫ aszinkron feldolgoz√°shoz.
Ez megoldja a Gateway Timeout probl√©m√°t √©s real-time progress tracking-et biztos√≠t.
"""

import os
import uuid
import redis
from rq import Queue, Worker
from typing import Dict, Any, Optional
import json
import time
from models import TaskStatus

# Flask-SocketIO import a WebSocket broadcast-hoz
try:
    from flask_socketio import SocketIO
except ImportError:
    # Fallback ha nincs Flask-SocketIO (pl. worker k√∂rnyezetben)
    SocketIO = None

# Redis kapcsolat konfigur√°l√°sa
redis_host = os.getenv('REDIS_HOST', 'localhost')
redis_port = int(os.getenv('REDIS_PORT', 6379))
redis_conn = redis.Redis(host=redis_host, port=redis_port)  # decode_responses=True elt√°vol√≠tva

# RQ queue l√©trehoz√°sa
task_queue = Queue('data_processing', connection=redis_conn)

class TaskManager:
    """Feladat √°llapot kezel≈ë oszt√°ly predikt√≠v ETA tracking-gel."""
    
    def __init__(self, socketio = None):
        self.redis_conn = redis_conn
        self.socketio = socketio
        # Throttling: csak 2 m√°sodpercenk√©nt friss√≠ts√ºk ugyanazt a task-ot
        self._last_update = {}
        # ETA tracking: kezd√©si id≈ëpontok t√°rol√°sa
        self._task_start_times = {}
    
    def create_task(self, task_type: str = "data_processing") -> str:
        """√öj feladat l√©trehoz√°sa egyedi ID-val."""
        task_id = str(uuid.uuid4())
        start_time = time.time()
        
        # Kezd√©si id≈ëpont t√°rol√°sa ETA sz√°m√≠t√°shoz
        self._task_start_times[task_id] = start_time
        
        initial_status = TaskStatus(
            task_id=task_id,
            status="pending",
            progress=0.0,
            message="Feladat l√©trehozva, v√°rakoz√°s ind√≠t√°sra...",
            start_time=start_time
        )
        
        self.redis_conn.set(
            f"task_status:{task_id}", 
            initial_status.json(),
            ex=3600  # 1 √≥r√°s lej√°rat
        )
        return task_id
    
    def update_progress(self, task_id: str, progress: float, message: str = "", 
                       processed_items: int = 0, relevant_found: int = 0, 
                       irrelevant_found: int = 0, total_items: Optional[int] = None):
        """Feladat halad√°s friss√≠t√©se throttling-gal √©s ETA sz√°m√≠t√°ssal."""
        # Throttling: ne friss√≠ts√ºk t√∫l gyakran ugyanazt a task-ot
        now = time.time()
        last_update = self._last_update.get(task_id, 0)
        
        # Csak 1 m√°sodpercenk√©nt enged√©lyezz√ºk a friss√≠t√©st, kiv√©ve ha 100% (befejezett)
        if progress < 100.0 and (now - last_update) < 1.0:
            return True
            
        self._last_update[task_id] = now
        
        # ETA sz√°m√≠t√°s
        start_time = self._task_start_times.get(task_id)
        elapsed_seconds = None
        eta_seconds = None
        items_per_second = None
        estimated_total_seconds = None
        
        if start_time and total_items and total_items > 0:
            elapsed_seconds = now - start_time
            
            # Csak akkor sz√°moljunk ETA-t ha van √©rtelmes halad√°s (> 1%)
            if processed_items > 0 and progress > 1.0:
                items_per_second = processed_items / elapsed_seconds
                remaining_items = total_items - processed_items
                
                if items_per_second > 0:
                    eta_seconds = remaining_items / items_per_second
                    estimated_total_seconds = elapsed_seconds + eta_seconds
        
        # Form√°zott ETA √ºzenet
        eta_message = ""
        if eta_seconds:
            if eta_seconds < 60:
                eta_message = f" | ETA: {int(eta_seconds)}s"
            elif eta_seconds < 3600:
                minutes = int(eta_seconds / 60)
                seconds = int(eta_seconds % 60)
                eta_message = f" | ETA: {minutes}m {seconds}s"
            else:
                hours = int(eta_seconds / 3600)
                minutes = int((eta_seconds % 3600) / 60)
                eta_message = f" | ETA: {hours}h {minutes}m"
        
        print(f"üîÑ Task Manager friss√≠t√©s: {progress:.1f}% - {message}{eta_message} | R:{relevant_found}, I:{irrelevant_found}", flush=True)
        
        current_status = self.get_status(task_id)
        if not current_status:
            return False
        
        updated_status = TaskStatus(
            task_id=task_id,
            status="running" if progress < 100.0 else "completed",
            progress=min(progress, 100.0),
            message=message or current_status.message,
            processed_items=processed_items,
            relevant_found=relevant_found,
            irrelevant_found=irrelevant_found,
            total_items=total_items or current_status.total_items,
            start_time=start_time,
            elapsed_seconds=elapsed_seconds,
            eta_seconds=eta_seconds,
            items_per_second=items_per_second,
            estimated_total_seconds=estimated_total_seconds
        )
        
        self.redis_conn.set(
            f"task_status:{task_id}",
            updated_status.json(),
            ex=3600
        )
        
        # WebSocket broadcast a real-time friss√≠t√©sekhez
        if self.socketio:
            try:
                self.socketio.emit('status_update', updated_status.model_dump(), room=task_id)
            except Exception as e:
                print(f"WebSocket broadcast hiba: {e}", flush=True)
        
        return True
    
    def set_status(self, task_id: str, status: str, message: str = ""):
        """Feladat st√°tusz be√°ll√≠t√°sa."""
        current_status = self.get_status(task_id)
        if not current_status:
            return False
        
        updated_status = TaskStatus(
            task_id=task_id,
            status=status,
            progress=current_status.progress,
            message=message or current_status.message,
            processed_items=current_status.processed_items,
            relevant_found=current_status.relevant_found,
            irrelevant_found=current_status.irrelevant_found,
            total_items=current_status.total_items
        )
        
        self.redis_conn.set(
            f"task_status:{task_id}",
            updated_status.json(),
            ex=3600
        )
        return True
    
    def get_status(self, task_id: str) -> Optional[TaskStatus]:
        """Feladat st√°tusz lek√©rdez√©se."""
        status_json = self.redis_conn.get(f"task_status:{task_id}")
        if not status_json:
            return None
        
        try:
            # Bytes to string konverzi√≥ ha sz√ºks√©ges
            if isinstance(status_json, bytes):
                status_json = status_json.decode('utf-8')
            status_data = json.loads(status_json)
            return TaskStatus(**status_data)
        except Exception:
            return None
    
    def mark_failed(self, task_id: str, error_message: str):
        """Feladat sikertelenk√©nt megjel√∂l√©se."""
        self.set_status(task_id, "failed", f"Hiba: {error_message}")
    
    def mark_completed(self, task_id: str, message: str = "Feldolgoz√°s sikeresen befejezve"):
        """Feladat befejezettk√©nt megjel√∂l√©se."""
        self.update_progress(task_id, 100.0, message)
        self.set_status(task_id, "completed", message)

def enqueue_data_processing_task(task_id: str, test_mode: bool = False) -> str:
    """Adatfeldolgoz√°si feladat be√ºtemez√©se a h√°tt√©rben.
    
    Args:
        task_id: A feladat azonos√≠t√≥ja
        test_mode: Ha True, akkor teszt m√≥dban fut (korl√°tozott elemsz√°m)
    """
    job = task_queue.enqueue(
        'background_tasks.process_data_async',
        task_id,
        test_mode,  # Teszt m√≥d flag √°tad√°sa
        job_timeout='2h',  # 2 √≥r√°s timeout (nagy adathalmazokhoz)
        job_id=task_id
    )
    return job.id

def get_queue_status() -> Dict[str, Any]:
    """Queue st√°tusz inform√°ci√≥k lek√©rdez√©se."""
    return {
        'pending_jobs': len(task_queue),
        'failed_jobs': len(task_queue.failed_job_registry),
        'scheduled_jobs': len(task_queue.scheduled_job_registry),
        'workers_count': Worker.count(queue=task_queue)
    }